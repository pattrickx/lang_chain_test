{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JBWzK_FgIsQP",
        "gTeDfZTRIv6g"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pattrickx/lang_chain_test/blob/main/langchain_load%2C_split_and_similarit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-KnTBPCG1mcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5fe0c4-b94d-497c-8e65-7fe389ce870e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -s \"/content/drive/MyDrive/My_projects/LangChain/data\" data"
      ],
      "metadata": {
        "id": "7yVV4y7d1p02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalation"
      ],
      "metadata": {
        "id": "bm4oADoeO1qK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install LangChain==0.1.12\n",
        "!pip install openai==1.14.1\n",
        "!pip install --upgrade --quiet  langchain-openai\n",
        "!pip install sentence-transformers\n",
        "!pip install jq\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "DwQ_iEmttS7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert string in document type"
      ],
      "metadata": {
        "id": "-l1IrEgsOwXA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eymbsVHsOKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1287e372-304f-4966-b0f4-ad4399d259e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='I want to use a langchain with a string instead of a txt file, is this possible?')]\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.schema.document import Document\n",
        "\n",
        "\n",
        "def get_text_chunks_langchain(text):\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "    docs = [Document(page_content=x) for x in text_splitter.split_text(text)]\n",
        "    return docs\n",
        "\n",
        "\n",
        "def main():\n",
        "    text = \"I want to use a langchain with a string instead of a txt file, is this possible?\"\n",
        "    docs = get_text_chunks_langchain(text)\n",
        "    print(docs)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Document from json"
      ],
      "metadata": {
        "id": "n48Nkd0sOtRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import JSONLoader"
      ],
      "metadata": {
        "id": "w-WzJdDr2ccL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the metadata extraction function.\n",
        "def metadata_func(record: dict, metadata: dict) -> dict:\n",
        "\n",
        "    metadata[\"page\"] = record.get(\"page\")\n",
        "    # metadata[\"timestamp_ms\"] = record.get(\"timestamp_ms\")\n",
        "\n",
        "    return metadata\n",
        "\n",
        "\n",
        "loader = JSONLoader(\n",
        "    file_path='/content/data/pages.json',\n",
        "    jq_schema='.[]',\n",
        "    content_key=\"content\",\n",
        "    metadata_func=metadata_func\n",
        ")\n",
        "\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "NSLqrOaA4mdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "fCQFyw3qBiK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Sep documents"
      ],
      "metadata": {
        "id": "rELymUvPOpWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "vsyMcmZQCExl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1000)\n",
        "# documents_splitted = text_splitter.split_documents(data)\n",
        "\n",
        "text_splitter_tiktoken = CharacterTextSplitter.from_tiktoken_encoder(separator=\"\\n\",chunk_size=400)\n",
        "documents_splitted = text_splitter_tiktoken.split_documents(data)"
      ],
      "metadata": {
        "id": "9qEuyyp8I9og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents_splitted"
      ],
      "metadata": {
        "id": "lwyWHJiAJgFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeding"
      ],
      "metadata": {
        "id": "ks_d2TlmOnIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "id": "rW3wemEaVaEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import SpacyEmbeddings\n",
        "embeddings = SpacyEmbeddings(model_name=\"pt_core_news_sm\")"
      ],
      "metadata": {
        "id": "oiOEW6D6JhFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_result = embeddings.embed_documents([part.page_content for part in documents_splitted])"
      ],
      "metadata": {
        "id": "lz43kVKnOAZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_result"
      ],
      "metadata": {
        "id": "sP1huMWnOUXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector storage: \"chromadb\""
      ],
      "metadata": {
        "id": "73O2di91O3mK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb==0.4.24\n",
        "!pip install --upgrade --quiet  spacy"
      ],
      "metadata": {
        "id": "Bwglu5KnO5Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb"
      ],
      "metadata": {
        "id": "y85vBDrJPEMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "PS3bOdFNPRYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = Chroma.from_documents(documents_splitted,embeddings,persist_directory=\"./speech_new_db_spacy\")\n",
        "db.persist()"
      ],
      "metadata": {
        "id": "yQeJhfVQPx7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conectar ao db\n",
        "db_new_connection = Chroma(persist_directory=\"./speech_new_db_spacy\",embedding_function=embeddings)"
      ],
      "metadata": {
        "id": "hke9zr8lRVDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \" retorne texto relacionado a testes substantivs e abordagem dual\""
      ],
      "metadata": {
        "id": "p-A6skYIRrGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_docs = db_new_connection.similarity_search(prompt) # Buscar documentoos mais semelhantes"
      ],
      "metadata": {
        "id": "sng7vyvDSYL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_docs"
      ],
      "metadata": {
        "id": "--gU4p-6V_Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# multi query"
      ],
      "metadata": {
        "id": "ysrzkd6_e6ZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade accelerate"
      ],
      "metadata": {
        "id": "eEcDSkQKGLHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Usar GPT4"
      ],
      "metadata": {
        "id": "JBWzK_FgIsQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "model_name = \"gpt-unifor\"\n",
        "os.environ[\"OPENAI_API_VERSION\"] = \"\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "XnuRzSa-I70f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import HumanMessage\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "llm = AzureChatOpenAI(\n",
        "    model_name=model_name,\n",
        "    temperature=0.0\n",
        ")\n"
      ],
      "metadata": {
        "id": "xw6KIgXVI4jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Usar model Local"
      ],
      "metadata": {
        "id": "gTeDfZTRIv6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "# from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "# model_id = \"GreenBitAI/LLaMA-2-1.1B-2bit-groupsize8\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_id,temperature=0.5,device_map=\"auto\")\n",
        "# pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=1000)\n",
        "# llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "5-MupFLCA1EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rodar Multi query"
      ],
      "metadata": {
        "id": "4l8maxfaIz1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever"
      ],
      "metadata": {
        "id": "F5pO3UbHBR7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_from_llm = MultiQueryRetriever.from_llm(retriever=db_new_connection.as_retriever(),llm=llm)"
      ],
      "metadata": {
        "id": "othxzH-3CZF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.basicConfig()\n",
        "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "7AxsqmEMC7eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_docs = retriever_from_llm.get_relevant_documents(query=\"Quem esta na reunião?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6-Xe0HIDXrO",
        "outputId": "441278ab-66bf-4393-ca57-e13ee8938675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:langchain.retrievers.multi_query:Generated queries: ['1. Quais são os participantes presentes na reunião atual?', '2. Poderia me informar os nomes das pessoas na reunião?', '3. Quem são os indivíduos que estão participando da reunião?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_docs"
      ],
      "metadata": {
        "id": "g-qVC1-cHx9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Context Compression"
      ],
      "metadata": {
        "id": "UZlMVdBqKhXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n"
      ],
      "metadata": {
        "id": "9w4Bn0L6Kp7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressor = LLMChainExtractor.from_llm(llm)\n",
        "\n",
        "compression_retriver = ContextualCompressionRetriever(base_compressor=compressor,\n",
        "                                                      base_retriever=db_new_connection.as_retriever())"
      ],
      "metadata": {
        "id": "havihRZgLG2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_docs = compression_retriver.get_relevant_documents(query=\"Quem esta na reunião?\")"
      ],
      "metadata": {
        "id": "pfRVEEvTLlvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_docs"
      ],
      "metadata": {
        "id": "mlewwH2uL07t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chains"
      ],
      "metadata": {
        "id": "Slxl-FbkMYGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate"
      ],
      "metadata": {
        "id": "_0UcENi0MZVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_template = SystemMessagePromptTemplate.from_template(\"voce é uma IA que auxilia na buca de informação e responde de forma resumida\")\n",
        "human_prompt_template = HumanMessagePromptTemplate.from_template(\"Use o contexto para responder a pergunta:\\n{context}\\nPergunta: {question}\")\n",
        "chat_prompt_template = ChatPromptTemplate.from_messages([system_prompt_template,human_prompt_template])"
      ],
      "metadata": {
        "id": "IW1f8K5fPBlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm"
      ],
      "metadata": {
        "id": "7eAXiyl7SFRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "0YrhxwRsSLD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=chat_prompt_template)"
      ],
      "metadata": {
        "id": "mdwsgBg6SUvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question=\"Quem esta na reunião?\"\n",
        "context = \"\\n\".join(document.page_content for document in compressed_docs)\n",
        "chain.run(question=question, context=context)"
      ],
      "metadata": {
        "id": "58PbESSSSb_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain, SimpleSequentialChain"
      ],
      "metadata": {
        "id": "N-iA4W9-SsHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QA Chain"
      ],
      "metadata": {
        "id": "3E2HRQCegaLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conectar ao db\n",
        "from langchain.embeddings import SpacyEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "embeddings = SpacyEmbeddings(model_name=\"pt_core_news_sm\")\n",
        "db_new_connection = Chroma(persist_directory=\"./speech_new_db_spacy\",embedding_function=embeddings)"
      ],
      "metadata": {
        "id": "7_T2CVv-VFgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain"
      ],
      "metadata": {
        "id": "-kKwlwYAg27T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = load_qa_with_sources_chain(llm,chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "evGMIdXdhOB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question=\"Quem esta na reunião?\""
      ],
      "metadata": {
        "id": "nfY-ovuyh4im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = db_new_connection.similarity_search(question)"
      ],
      "metadata": {
        "id": "0J2cuS1zhuZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain.run(input_documents=docs,question=question)"
      ],
      "metadata": {
        "id": "ufizTC-Nh7JY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}